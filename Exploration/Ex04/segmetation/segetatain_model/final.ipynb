{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d22c76ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31merror\u001b[39m                                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     15\u001b[39m img_path = os.path.join(os.getenv(\u001b[33m'\u001b[39m\u001b[33mUSERPROFILE\u001b[39m\u001b[33m'\u001b[39m), \u001b[33m'\u001b[39m\u001b[33mDesktop\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33maiffel\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33msegmetation\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mimages\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mimage3.png\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     16\u001b[39m img_orig = cv2.imread(img_path)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m img_rgb = \u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_orig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCOLOR_BGR2RGB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# [STEP 1] DeepLabv3로 인물 마스크 생성 후 가장 큰 인물만 선택\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlargest_person_mask\u001b[39m(image_bgr):\n",
      "\u001b[31merror\u001b[39m: OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.models.segmentation import deeplabv3_resnet101\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import measure  # 연결된 컴포넌트 분석을 위한 모듈\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# [STEP 0] 이미지 로드\n",
    "img_path = os.path.join(os.getenv('USERPROFILE'), 'Desktop', 'aiffel', 'segmetation', 'images', 'image3.png')\n",
    "img_orig = cv2.imread(img_path)\n",
    "img_rgb = cv2.cvtColor(img_orig, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# [STEP 1] DeepLabv3로 인물 마스크 생성 후 가장 큰 인물만 선택\n",
    "def largest_person_mask(image_bgr):\n",
    "    model = deeplabv3_resnet101(pretrained=True).to(device).eval()\n",
    "    transform = Compose([\n",
    "        ToTensor(),\n",
    "        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    input_tensor = transform(cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)['out'][0]\n",
    "        mask = output.argmax(0).byte().cpu().numpy()\n",
    "    \n",
    "    # 인물 클래스(15)에 해당하는 마스크 추출\n",
    "    person_mask = (mask == 15).astype(np.uint8)\n",
    "    \n",
    "    # 연결된 컴포넌트 레이블링으로 서로 다른 인물 구분\n",
    "    labels = measure.label(person_mask)\n",
    "    regions = measure.regionprops(labels)\n",
    "    \n",
    "    if not regions:  # 인물이 없는 경우\n",
    "        return np.zeros_like(person_mask)\n",
    "    \n",
    "    # 가장 큰 영역(인물) 선택\n",
    "    largest_region = max(regions, key=lambda r: r.area)\n",
    "    largest_person_mask = np.zeros_like(person_mask)\n",
    "    largest_person_mask[labels == largest_region.label] = 1\n",
    "    \n",
    "    # 마스크 후처리로 잡음 제거 및 경계 부드럽게\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    largest_person_mask = cv2.morphologyEx(largest_person_mask.astype(np.uint8), cv2.MORPH_CLOSE, kernel) * 255\n",
    "    \n",
    "    return largest_person_mask\n",
    "\n",
    "# 마스크 생성 및 시각화 함수\n",
    "def visualize_masks(core_mask, feather_mask, bg_mask, original_img):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # 원본 이미지\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.imshow(cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Core 영역 시각화\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.imshow(core_mask, cmap='gray')\n",
    "    plt.title(\"Core Mask (Main Person)\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Feather 영역 시각화\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.imshow(feather_mask, cmap='gray')\n",
    "    plt.title(\"Feather Mask\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Background 영역 시각화\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.imshow(bg_mask, cmap='gray')\n",
    "    plt.title(\"Background Mask\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 가장 큰 인물 마스크 생성 및 처리\n",
    "# 차이점 - 마스크 생성 방식 (임계값 조정)\n",
    "mask = largest_person_mask(img_orig)\n",
    "mask_blur = cv2.GaussianBlur(mask, (31, 31), 0)# 블러 커널 크기 증가\n",
    "\n",
    "# Core, Feather, Background 영역 분리\n",
    "# Core/Feather 영역 분리 방식 개선\n",
    "core_mask = (mask_blur > 150).astype(np.uint8) * 255  # 임계값 낮춤으로 더 많은 영역 포함\n",
    "feather_mask = ((mask_blur > 5) & (mask_blur <= 150)).astype(np.uint8) * 255\n",
    "bg_mask = (mask_blur <= 5).astype(np.uint8) * 255\n",
    "\n",
    "# 마스크 시각화 호출\n",
    "visualize_masks(core_mask, feather_mask, bg_mask, img_orig)\n",
    "\n",
    "# [STEP 2] MiDaS로 depth map 생성 및 개선\n",
    "# 차이점 -MiDaS 깊이 추정 + 양방향 필터링 추가\n",
    "def estimate_depth_midas(img):\n",
    "    midas = torch.hub.load(\"intel-isl/MiDaS\", \"DPT_Hybrid\").to(device).eval()\n",
    "    transform = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\").dpt_transform\n",
    "    img_transformed = transform(img).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        prediction = midas(img_transformed)\n",
    "        depth = prediction.squeeze().cpu().numpy()\n",
    "        # 깊이 맵 품질 개선을 위한 양방향 필터링\n",
    "        depth_filtered = cv2.bilateralFilter(depth.astype(np.float32), d=9, sigmaColor=75, sigmaSpace=75)\n",
    "        depth_normalized = cv2.normalize(depth_filtered, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "        return depth_normalized\n",
    "\n",
    "depth_map = estimate_depth_midas(img_rgb)\n",
    "\n",
    "# 깊이 맵 시각화\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(depth_map, cmap='plasma')\n",
    "plt.title(\"Depth Map\")\n",
    "plt.axis('off')\n",
    "plt.colorbar(label='Depth')\n",
    "plt.show()\n",
    "\n",
    "# [STEP 3] 블러 및 블렌딩 적용\n",
    "# 차이점 - 블렌딩 알고리즘 (선명도 보정)\n",
    "def blur_with_feathering(img, depth_map, core_mask, feather_mask, bg_mask):\n",
    "    depth_resized = cv2.resize(depth_map, (img.shape[1], img.shape[0]))\n",
    "    \n",
    "    # 강한 배경 블러 적용 (61x61 커널)\n",
    "    img_blur = cv2.GaussianBlur(img, (61, 61), 0)  # 강한 블러 효과\n",
    "    \n",
    "    # 3채널 마스크 변환\n",
    "    core_3ch = cv2.cvtColor(core_mask, cv2.COLOR_GRAY2BGR)\n",
    "    feather_3ch = cv2.cvtColor(feather_mask, cv2.COLOR_GRAY2BGR)\n",
    "    bg_3ch = cv2.cvtColor(bg_mask, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    # Feather 영역 블렌딩 - 선명도 증가\n",
    "    feather_alpha = feather_mask.astype(np.float32) / 255.0\n",
    "    feather_alpha = feather_alpha[:, :, np.newaxis] * 0.8 + 0.2  # 선명도 증가\n",
    "    feather_blended = (img * feather_alpha + img_blur * (1 - feather_alpha)).astype(np.uint8)\n",
    "    \n",
    "    # 최종 합성\n",
    "    final_img = np.zeros_like(img)\n",
    "    final_img = np.where(core_3ch > 0, img, final_img)  # Core는 원본 유지\n",
    "    final_img = np.where(feather_3ch > 0, feather_blended, final_img)  # Feather는 블렌딩\n",
    "    final_img = np.where(bg_3ch > 0, img_blur, final_img)  # Background는 강한 블러\n",
    "    \n",
    "    return final_img\n",
    "final_img = blur_with_feathering(img_orig, depth_map, core_mask, feather_mask, bg_mask)\n",
    "\n",
    "# [STEP 4] 기본 배경 교체\n",
    "def replace_background(img, new_bg_path, core_mask, feather_mask, bg_mask):\n",
    "    # 새 배경 이미지 로드\n",
    "    new_bg = cv2.imread(new_bg_path)\n",
    "    \n",
    "    # 원본 이미지 크기에 맞게 배경 조정\n",
    "    new_bg = cv2.resize(new_bg, (img.shape[1], img.shape[0]))\n",
    "    \n",
    "    # 3채널 마스크 변환\n",
    "    core_3ch = cv2.cvtColor(core_mask, cv2.COLOR_GRAY2BGR)\n",
    "    feather_3ch = cv2.cvtColor(feather_mask, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    # Feather 영역 블렌딩을 위한 알파값 계산\n",
    "    feather_alpha = feather_mask.astype(np.float32) / 255.0\n",
    "    feather_alpha = feather_alpha[:, :, np.newaxis]\n",
    "    \n",
    "    # Feather 영역 블렌딩 - 원본과 새 배경 사이 자연스러운 전환\n",
    "    feather_blended = (img * feather_alpha + new_bg * (1 - feather_alpha)).astype(np.uint8)\n",
    "    \n",
    "    # 최종 합성\n",
    "    final_img = np.zeros_like(img)\n",
    "    final_img = np.where(core_3ch > 0, img, final_img)  # Core는 원본 유지\n",
    "    final_img = np.where(feather_3ch > 0, feather_blended, final_img)  # Feather는 블렌딩\n",
    "    final_img = np.where((core_3ch == 0) & (feather_3ch == 0), new_bg, final_img)  # 나머지는 새 배경\n",
    "    \n",
    "    return final_img\n",
    "\n",
    "# [STEP 5] 배경 교체2\n",
    "def background_replace(img, new_bg_path, core_mask, feather_mask, depth_map):\n",
    "    # 새 배경 이미지 로드\n",
    "    new_bg = cv2.imread(new_bg_path)\n",
    "    new_bg = cv2.resize(new_bg, (img.shape[1], img.shape[0]))\n",
    "    \n",
    "    # 원본 이미지와 새 배경의 색상 분포 조정 (색상 일관성)\n",
    "    foreground_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    background_hsv = cv2.cvtColor(new_bg, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # 전경의 평균 색상 계산\n",
    "    fg_mask = (core_mask > 0).astype(np.uint8)\n",
    "    fg_hsv_mean = np.array([\n",
    "        np.mean(foreground_hsv[:, :, 0][fg_mask > 0]),\n",
    "        np.mean(foreground_hsv[:, :, 1][fg_mask > 0]),\n",
    "        np.mean(foreground_hsv[:, :, 2][fg_mask > 0])\n",
    "    ])\n",
    "    \n",
    "    # 배경의 평균 색상 계산\n",
    "    bg_hsv_mean = np.array([\n",
    "        np.mean(background_hsv[:, :, 0]),\n",
    "        np.mean(background_hsv[:, :, 1]),\n",
    "        np.mean(background_hsv[:, :, 2])\n",
    "    ])\n",
    "    \n",
    "    # 색상 조정 가중치 (HSV 조정)\n",
    "    color_adjustment = (fg_hsv_mean - bg_hsv_mean) * 0.3\n",
    "    \n",
    "    # 새 배경 색상 조정\n",
    "    background_hsv[:, :, 0] = np.clip(background_hsv[:, :, 0] + color_adjustment[0], 0, 179)\n",
    "    background_hsv[:, :, 1] = np.clip(background_hsv[:, :, 1] + color_adjustment[1], 0, 255)\n",
    "    background_hsv[:, :, 2] = np.clip(background_hsv[:, :, 2] + color_adjustment[2], 0, 255)\n",
    "    \n",
    "    # HSV에서 BGR로 변환\n",
    "    adjusted_bg = cv2.cvtColor(background_hsv, cv2.COLOR_HSV2BGR)\n",
    "    \n",
    "    # 깊이 맵 기반 그림자 효과 추가\n",
    "    depth_resized = cv2.resize(depth_map, (img.shape[1], img.shape[0]))\n",
    "    depth_norm = depth_resized / 255.0  # 정규화\n",
    "    \n",
    "    # 그림자 강도 (낮은 깊이 = 강한 그림자)\n",
    "    shadow_strength = 0.7 * (1 - depth_norm)[:, :, np.newaxis]\n",
    "    shadow_strength = shadow_strength * 0.4  # 그림자 강도 조절\n",
    "    \n",
    "    # 3채널 마스크\n",
    "    core_3ch = cv2.cvtColor(core_mask, cv2.COLOR_GRAY2BGR) / 255.0\n",
    "    feather_3ch = cv2.cvtColor(feather_mask, cv2.COLOR_GRAY2BGR) / 255.0\n",
    "    \n",
    "    # Feather 영역 블렌딩\n",
    "    feather_alpha = feather_3ch\n",
    "    \n",
    "    # 그림자 적용 배경\n",
    "    shadowed_bg = adjusted_bg * (1 - shadow_strength)\n",
    "    \n",
    "    # 최종 블렌딩\n",
    "    blended = img * core_3ch + \\\n",
    "              img * feather_alpha + shadowed_bg * (1 - feather_alpha - core_3ch)\n",
    "    \n",
    "    return blended.astype(np.uint8)\n",
    "\n",
    "\n",
    "# 새 배경 이미지 경로 설정\n",
    "new_background_path = os.path.join(os.getenv('USERPROFILE'), 'Desktop', 'aiffel', 'segmetation', 'images', 'bg_image3.png')\n",
    "# 만약 beach.jpg 파일이 없다면, 사용 가능한 다른 배경 이미지 경로로 변경하세요\n",
    "\n",
    "replaced_bg_img = replace_background(\n",
    "    img_orig, \n",
    "    new_background_path, \n",
    "    core_mask, \n",
    "    feather_mask, \n",
    "    bg_mask\n",
    ")\n",
    "\n",
    "# 고급 배경 교체 적용\n",
    "background_replaced_img = background_replace(\n",
    "    img_orig, \n",
    "    new_background_path, \n",
    "    core_mask, \n",
    "    feather_mask, \n",
    "    depth_map\n",
    ")\n",
    "\n",
    "# 원본과 결과 비교 시각화\n",
    "plt.figure(figsize=(20, 8))\n",
    "\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(cv2.cvtColor(img_orig, cv2.COLOR_BGR2RGB))\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.imshow(cv2.cvtColor(final_img, cv2.COLOR_BGR2RGB))\n",
    "plt.title(\"Feather Blending + Blur\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.imshow(cv2.cvtColor(replaced_bg_img, cv2.COLOR_BGR2RGB))\n",
    "plt.title(\"background Replace1\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.imshow(cv2.cvtColor(background_replaced_img, cv2.COLOR_BGR2RGB))\n",
    "plt.title(\"background Replace2\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4f6f74",
   "metadata": {},
   "source": [
    "**결과물1**\n",
    "변경 전 이미지\n",
    "![0.png](./0.png)\n",
    "함수적용\n",
    "![01.png](./01.png)\n",
    "![02.png](./02.png)\n",
    "적용 후 이미지\n",
    "![03.png](./03.png)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63707c5c",
   "metadata": {},
   "source": [
    "**결과물2**\n",
    "함수적용\n",
    "![001.png](./001.png)\n",
    "![002.png](./002.png)\n",
    "적용 후 이미지\n",
    "![003.png](./003.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947ab68b",
   "metadata": {},
   "source": [
    "**결과물3**\n",
    "함수적용\n",
    "![1.png](./1.png)\n",
    "![2.png](./2.png)\n",
    "적용 후 이미지\n",
    "![3.png](./3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431a4b86",
   "metadata": {},
   "source": [
    "# 코드 진행 방식\n",
    "[STEP 0] 이미지 로드\n",
    "     ↓\n",
    "[STEP 1] 인물 마스크 추출\n",
    "     ↓\n",
    "[STEP 2] 배경 복원 (피사체 제거 & inpaint)\n",
    "     ↓\n",
    "[STEP 3] 배경 스타일링 (채도, 하늘, 톤)\n",
    "     ↓\n",
    "[STEP 4] 피사체 부드럽게 처리\n",
    "     ↓\n",
    "[STEP 5] 재합성 (톤 맞추기, 그림자, 블렌딩)\n",
    "     ↓\n",
    "[OPTION] LUT / 전체 색감 조정\n",
    "     ↓\n",
    "출력: 배경 중심의 고급스러운 풍경 인물 사진\n",
    "\n",
    "**[STEP 0] 이미지 로드**\n",
    "cv2.imread로 이미지를 로드하고 RGB 형식으로 변환합니다.\n",
    "\n",
    "이미지 경로는 사용자 환경변수(USERPROFILE)를 기반으로 설정됩니다.\n",
    "\n",
    "**[STEP 1] 가장 큰 인물 마스크 생성**\n",
    "DeepLabv3 모델(deeplabv3_resnet101)을 사용하여 이미지의 세그멘테이션 결과를 얻습니다.\n",
    "\n",
    "인물 클래스(15)에 해당하는 마스크를 추출하고, skimage.measure 모듈로 연결된 컴포넌트 분석을 수행해 가장 큰 영역(인물)을 선택합니다.\n",
    "\n",
    "선택된 마스크는 후처리를 통해 잡음을 제거하고 경계를 부드럽게 만듭니다.\n",
    "\n",
    "**[STEP 2] 깊이 맵 생성**\n",
    "MiDaS 모델(DPT_Hybrid)을 사용하여 이미지의 깊이 정보를 추출합니다.\n",
    "\n",
    "양방향 필터링(cv2.bilateralFilter)을 통해 깊이 맵의 품질을 개선하고, 정규화하여 시각적으로 표현 가능한 형태로 변환합니다.\n",
    "\n",
    "**[STEP 3] 블러 및 블렌딩 효과 적용**\n",
    "Gaussian Blur를 사용해 배경에 강한 블러 효과를 적용합니다.\n",
    "\n",
    "Core 영역(인물)은 원본 이미지를 유지하고, Feather 영역(경계)은 원본과 블러 이미지를 자연스럽게 블렌딩하며, 배경은 강한 블러만 적용됩니다.\n",
    "\n",
    "**[STEP 4] 기본 배경 교체**\n",
    "새 배경 이미지를 로드하고 원본 이미지 크기에 맞게 조정합니다.\n",
    "\n",
    "Feather 영역은 원본과 새 배경 사이를 부드럽게 전환하며, Core 영역은 원본 이미지를 그대로 유지합니다.\n",
    "\n",
    "**[STEP 5] 고급 배경 교체**\n",
    "새 배경의 색상을 원본 이미지와 일치시키기 위해 HSV 색상 조정을 수행합니다.\n",
    "\n",
    "깊이 맵 정보를 활용해 그림자 효과를 추가하여 더 현실감 있는 결과를 만듭니다.\n",
    "\n",
    "최종적으로 Core, Feather, 그림자 효과가 반영된 새 배경 이미지를 합성합니다.\n",
    "\n",
    "# 차이점:\n",
    "**정확한 인물 선택**\n",
    "\n",
    "연결된 컴포넌트 분석(skimage.measure) 추가로 다중 인물 환경에서 가장 큰 인물 정확히 선택\n",
    "\n",
    "모폴로지 연산(cv2.MORPH_CLOSE)으로 마스크 경계 개선\n",
    "\n",
    "**깊이 처리 개선**\n",
    "\n",
    "MiDaS 깊이 맵 + 양방향 필터링 적용으로 노이즈 감소\n",
    "\n",
    "깊이 기반 그림자 효과 추가\n",
    "\n",
    "**자연스러운 합성**\n",
    "\n",
    "HSV 색상 공간에서의 색상 보정\n",
    "\n",
    "3채널 마스크와 계층적 블렌딩\n",
    "\n",
    "Feather 영역 가중치 조정(0.8 → 0.2)으로 선명도 향상\n",
    "\n",
    "**시각화 강화**\n",
    "\n",
    "Core/Feather/Background 마스크 분리 표시\n",
    "\n",
    "4-way 비교 시각화(원본, 블러, 기본 교체, 고급 교체)\n",
    "\n",
    "**성능 최적화**\n",
    "\n",
    "GPU 가속 지원 강화\n",
    "\n",
    "큰 커널 사이즈(61x61) 사용으로 배경 블러 품질 향상"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
